{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The aim is to implement a machine learning model to identify the language a document is written in. \n",
    "\n",
    "# Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is WiLI-2018, the Wikipedia language identification benchmark dataset, contains 235000 paragraphs of 235 languages. A subset of this dataset from kaggle, having 22 languages are used here for modeling.\n",
    "\n",
    "https://www.kaggle.com/zarajamshaid/language-identification-datasst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T17:58:17.086348Z",
     "iopub.status.busy": "2021-06-30T17:58:17.086001Z",
     "iopub.status.idle": "2021-06-30T17:58:17.300894Z",
     "shell.execute_reply": "2021-06-30T17:58:17.299864Z",
     "shell.execute_reply.started": "2021-06-30T17:58:17.086317Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T17:58:17.303569Z",
     "iopub.status.busy": "2021-06-30T17:58:17.303237Z",
     "iopub.status.idle": "2021-06-30T17:58:17.321133Z",
     "shell.execute_reply": "2021-06-30T17:58:17.319985Z",
     "shell.execute_reply.started": "2021-06-30T17:58:17.303537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T17:58:17.322640Z",
     "iopub.status.busy": "2021-06-30T17:58:17.322310Z",
     "iopub.status.idle": "2021-06-30T17:58:17.404941Z",
     "shell.execute_reply": "2021-06-30T17:58:17.403786Z",
     "shell.execute_reply.started": "2021-06-30T17:58:17.322606Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='Text')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T17:58:17.407020Z",
     "iopub.status.busy": "2021-06-30T17:58:17.406449Z",
     "iopub.status.idle": "2021-06-30T17:58:17.422816Z",
     "shell.execute_reply": "2021-06-30T17:58:17.421335Z",
     "shell.execute_reply.started": "2021-06-30T17:58:17.406969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       1000\n",
       "Urdu          1000\n",
       "Japanese      1000\n",
       "Persian       1000\n",
       "Korean        1000\n",
       "Turkish       1000\n",
       "Chinese       1000\n",
       "Romanian      1000\n",
       "Thai          1000\n",
       "Russian        999\n",
       "Estonian       999\n",
       "Arabic         998\n",
       "Portugese      997\n",
       "Spanish        996\n",
       "Dutch          996\n",
       "Pushto         993\n",
       "Swedish        992\n",
       "French         990\n",
       "Hindi          990\n",
       "Tamil          981\n",
       "Indonesian     975\n",
       "Latin          953\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T17:58:17.427016Z",
     "iopub.status.busy": "2021-06-30T17:58:17.426581Z",
     "iopub.status.idle": "2021-06-30T17:58:17.441801Z",
     "shell.execute_reply": "2021-06-30T17:58:17.440620Z",
     "shell.execute_reply.started": "2021-06-30T17:58:17.426984Z"
    }
   },
   "outputs": [],
   "source": [
    "train_doc,test_doc,train_labels,test_labels = train_test_split(df['Text'].values,df['language'].values,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Features\n",
    "\n",
    "Count vectors of character level n-grams for a range upto 4 of input text is used as features. Converting the input text to n-gram is called tokenization. \n",
    "\n",
    "For example, the features for word $'match'$ are $ m , ma, mat, matc, a, at, atc, atch, t, tc, tch, c, ch, h$\n",
    "\n",
    "Countvectorization is the most basic method of transforming words into vectors by counting occurrence of each character ngram in each document. The output is a document-term matrix with each row representing a document and each column addressing a token (weight assigned to each token based on counting the occurence).\n",
    "\n",
    "We use training data to built vocabulory for count vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T17:58:17.443877Z",
     "iopub.status.busy": "2021-06-30T17:58:17.443539Z",
     "iopub.status.idle": "2021-06-30T17:58:17.464962Z",
     "shell.execute_reply": "2021-06-30T17:58:17.463773Z",
     "shell.execute_reply.started": "2021-06-30T17:58:17.443845Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,4),analyzer='char',max_features=25000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T17:58:17.467760Z",
     "iopub.status.busy": "2021-06-30T17:58:17.467344Z",
     "iopub.status.idle": "2021-06-30T17:59:00.115372Z",
     "shell.execute_reply": "2021-06-30T17:59:00.114226Z",
     "shell.execute_reply.started": "2021-06-30T17:58:17.467720Z"
    }
   },
   "outputs": [],
   "source": [
    "vector = vectorizer.fit_transform(train_doc)\n",
    "train_df= pd.DataFrame(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "RandomForest model is used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T17:59:00.117348Z",
     "iopub.status.busy": "2021-06-30T17:59:00.117025Z",
     "iopub.status.idle": "2021-06-30T18:04:44.316138Z",
     "shell.execute_reply": "2021-06-30T18:04:44.315370Z",
     "shell.execute_reply.started": "2021-06-30T17:59:00.117317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(train_df.values,train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T04:54:42.598124Z",
     "iopub.status.busy": "2021-06-30T04:54:42.59763Z",
     "iopub.status.idle": "2021-06-30T04:54:42.6034Z",
     "shell.execute_reply": "2021-06-30T04:54:42.602005Z",
     "shell.execute_reply.started": "2021-06-30T04:54:42.598089Z"
    }
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T18:04:44.317950Z",
     "iopub.status.busy": "2021-06-30T18:04:44.317409Z",
     "iopub.status.idle": "2021-06-30T18:04:53.594432Z",
     "shell.execute_reply": "2021-06-30T18:04:53.593709Z",
     "shell.execute_reply.started": "2021-06-30T18:04:44.317911Z"
    }
   },
   "outputs": [],
   "source": [
    "vector_test = vectorizer.transform(test_doc)\n",
    "test_df = pd.DataFrame(vector_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T18:04:53.596173Z",
     "iopub.status.busy": "2021-06-30T18:04:53.595666Z",
     "iopub.status.idle": "2021-06-30T18:04:58.236243Z",
     "shell.execute_reply": "2021-06-30T18:04:58.235186Z",
     "shell.execute_reply.started": "2021-06-30T18:04:53.596141Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T18:04:58.237969Z",
     "iopub.status.busy": "2021-06-30T18:04:58.237652Z",
     "iopub.status.idle": "2021-06-30T18:04:58.542778Z",
     "shell.execute_reply": "2021-06-30T18:04:58.541745Z",
     "shell.execute_reply.started": "2021-06-30T18:04:58.237939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      1.00      1.00       330\n",
      "     Chinese       0.99      0.98      0.99       301\n",
      "       Dutch       1.00      0.98      0.99       323\n",
      "     English       0.81      0.99      0.90       332\n",
      "    Estonian       0.99      0.97      0.98       317\n",
      "      French       0.97      1.00      0.98       320\n",
      "       Hindi       1.00      0.97      0.99       316\n",
      "  Indonesian       1.00      0.98      0.99       352\n",
      "    Japanese       1.00      0.98      0.99       302\n",
      "      Korean       1.00      0.99      0.99       355\n",
      "       Latin       0.93      0.94      0.93       326\n",
      "     Persian       1.00      1.00      1.00       330\n",
      "   Portugese       0.98      0.98      0.98       331\n",
      "      Pushto       1.00      0.96      0.98       305\n",
      "    Romanian       1.00      0.99      0.99       356\n",
      "     Russian       0.99      0.99      0.99       308\n",
      "     Spanish       1.00      0.96      0.98       353\n",
      "     Swedish       1.00      1.00      1.00       322\n",
      "       Tamil       1.00      0.99      0.99       316\n",
      "        Thai       1.00      0.99      1.00       329\n",
      "     Turkish       1.00      0.99      0.99       363\n",
      "        Urdu       1.00      0.98      0.99       327\n",
      "\n",
      "    accuracy                           0.98      7214\n",
      "   macro avg       0.98      0.98      0.98      7214\n",
      "weighted avg       0.98      0.98      0.98      7214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
